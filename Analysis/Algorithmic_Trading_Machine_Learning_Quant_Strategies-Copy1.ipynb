{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee7defea",
   "metadata": {},
   "source": [
    "# Unsupervised Learning Trading Strategy\n",
    "\n",
    "* Download/Load SP500 stocks prices data.\n",
    "* Calculate different features and indicators on each stock.\n",
    "* Aggregate on monthly level and filter top 150 most liquid stocks.\n",
    "* Calculate Monthly Returns for different time-horizons.\n",
    "* Download Fama-French Factors and Calculate Rolling Factor Betas.\n",
    "* For each month fit a K-Means Clustering Algorithm to group similar assets based on their features.\n",
    "* For each month select assets based on the cluster and form a portfolio based on Efficient Frontier max sharpe ratio optimization.\n",
    "* Visualize Portfolio returns and compare to SP500 returns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaf4331",
   "metadata": {},
   "source": [
    "# All Packages Needed:\n",
    "* pandas, numpy, matplotlib, statsmodels, pandas_datareader, pandas_ta, datetime, yfinance, sklearn, PyPortfolioOpt, arch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfeddf97",
   "metadata": {},
   "source": [
    "## 1. Download/Load SP500 stocks prices data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835a7260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.regression.rolling import RollingOLS\n",
    "import pandas_datareader.data as web\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import yfinance as yf\n",
    "import pandas_ta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f9d4e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Security</th>\n",
       "      <th>GICS Sector</th>\n",
       "      <th>GICS Sub-Industry</th>\n",
       "      <th>Headquarters Location</th>\n",
       "      <th>Date added</th>\n",
       "      <th>CIK</th>\n",
       "      <th>Founded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>3M</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrial Conglomerates</td>\n",
       "      <td>Saint Paul, Minnesota</td>\n",
       "      <td>1957-03-04</td>\n",
       "      <td>66740</td>\n",
       "      <td>1902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AOS</td>\n",
       "      <td>A. O. Smith</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Building Products</td>\n",
       "      <td>Milwaukee, Wisconsin</td>\n",
       "      <td>2017-07-26</td>\n",
       "      <td>91142</td>\n",
       "      <td>1916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABT</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment</td>\n",
       "      <td>North Chicago, Illinois</td>\n",
       "      <td>1957-03-04</td>\n",
       "      <td>1800</td>\n",
       "      <td>1888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>AbbVie</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Biotechnology</td>\n",
       "      <td>North Chicago, Illinois</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1551152</td>\n",
       "      <td>2013 (1888)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACN</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Consulting &amp; Other Services</td>\n",
       "      <td>Dublin, Ireland</td>\n",
       "      <td>2011-07-06</td>\n",
       "      <td>1467373</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>YUM</td>\n",
       "      <td>Yum! Brands</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>Louisville, Kentucky</td>\n",
       "      <td>1997-10-06</td>\n",
       "      <td>1041061</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>ZBRA</td>\n",
       "      <td>Zebra Technologies</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Electronic Equipment &amp; Instruments</td>\n",
       "      <td>Lincolnshire, Illinois</td>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>877212</td>\n",
       "      <td>1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>ZBH</td>\n",
       "      <td>Zimmer Biomet</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment</td>\n",
       "      <td>Warsaw, Indiana</td>\n",
       "      <td>2001-08-07</td>\n",
       "      <td>1136869</td>\n",
       "      <td>1927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>ZION</td>\n",
       "      <td>Zions Bancorporation</td>\n",
       "      <td>Financials</td>\n",
       "      <td>Regional Banks</td>\n",
       "      <td>Salt Lake City, Utah</td>\n",
       "      <td>2001-06-22</td>\n",
       "      <td>109380</td>\n",
       "      <td>1873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>Zoetis</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Pharmaceuticals</td>\n",
       "      <td>Parsippany, New Jersey</td>\n",
       "      <td>2013-06-21</td>\n",
       "      <td>1555280</td>\n",
       "      <td>1952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Symbol              Security             GICS Sector  \\\n",
       "0      MMM                    3M             Industrials   \n",
       "1      AOS           A. O. Smith             Industrials   \n",
       "2      ABT                Abbott             Health Care   \n",
       "3     ABBV                AbbVie             Health Care   \n",
       "4      ACN             Accenture  Information Technology   \n",
       "..     ...                   ...                     ...   \n",
       "498    YUM           Yum! Brands  Consumer Discretionary   \n",
       "499   ZBRA    Zebra Technologies  Information Technology   \n",
       "500    ZBH         Zimmer Biomet             Health Care   \n",
       "501   ZION  Zions Bancorporation              Financials   \n",
       "502    ZTS                Zoetis             Health Care   \n",
       "\n",
       "                      GICS Sub-Industry    Headquarters Location  Date added  \\\n",
       "0              Industrial Conglomerates    Saint Paul, Minnesota  1957-03-04   \n",
       "1                     Building Products     Milwaukee, Wisconsin  2017-07-26   \n",
       "2                 Health Care Equipment  North Chicago, Illinois  1957-03-04   \n",
       "3                         Biotechnology  North Chicago, Illinois  2012-12-31   \n",
       "4        IT Consulting & Other Services          Dublin, Ireland  2011-07-06   \n",
       "..                                  ...                      ...         ...   \n",
       "498                         Restaurants     Louisville, Kentucky  1997-10-06   \n",
       "499  Electronic Equipment & Instruments   Lincolnshire, Illinois  2019-12-23   \n",
       "500               Health Care Equipment          Warsaw, Indiana  2001-08-07   \n",
       "501                      Regional Banks     Salt Lake City, Utah  2001-06-22   \n",
       "502                     Pharmaceuticals   Parsippany, New Jersey  2013-06-21   \n",
       "\n",
       "         CIK      Founded  \n",
       "0      66740         1902  \n",
       "1      91142         1916  \n",
       "2       1800         1888  \n",
       "3    1551152  2013 (1888)  \n",
       "4    1467373         1989  \n",
       "..       ...          ...  \n",
       "498  1041061         1997  \n",
       "499   877212         1969  \n",
       "500  1136869         1927  \n",
       "501   109380         1873  \n",
       "502  1555280         1952  \n",
       "\n",
       "[503 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp500 = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')[0]\n",
    "sp500['Symbol'] = sp500['Symbol'].str.replace('.', '-')\n",
    "sp500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2c78426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MMM',\n",
       " 'AOS',\n",
       " 'ABT',\n",
       " 'ABBV',\n",
       " 'ACN',\n",
       " 'ADBE',\n",
       " 'AMD',\n",
       " 'AES',\n",
       " 'AFL',\n",
       " 'A',\n",
       " 'APD',\n",
       " 'ABNB',\n",
       " 'AKAM',\n",
       " 'ALB',\n",
       " 'ARE',\n",
       " 'ALGN',\n",
       " 'ALLE',\n",
       " 'LNT',\n",
       " 'ALL',\n",
       " 'GOOGL',\n",
       " 'GOOG',\n",
       " 'MO',\n",
       " 'AMZN',\n",
       " 'AMCR',\n",
       " 'AEE',\n",
       " 'AAL',\n",
       " 'AEP',\n",
       " 'AXP',\n",
       " 'AIG',\n",
       " 'AMT',\n",
       " 'AWK',\n",
       " 'AMP',\n",
       " 'AME',\n",
       " 'AMGN',\n",
       " 'APH',\n",
       " 'ADI',\n",
       " 'ANSS',\n",
       " 'AON',\n",
       " 'APA',\n",
       " 'AAPL',\n",
       " 'AMAT',\n",
       " 'APTV',\n",
       " 'ACGL',\n",
       " 'ADM',\n",
       " 'ANET',\n",
       " 'AJG',\n",
       " 'AIZ',\n",
       " 'T',\n",
       " 'ATO',\n",
       " 'ADSK',\n",
       " 'ADP',\n",
       " 'AZO',\n",
       " 'AVB',\n",
       " 'AVY',\n",
       " 'AXON',\n",
       " 'BKR',\n",
       " 'BALL',\n",
       " 'BAC',\n",
       " 'BK',\n",
       " 'BBWI',\n",
       " 'BAX',\n",
       " 'BDX',\n",
       " 'BRK-B',\n",
       " 'BBY',\n",
       " 'BIO',\n",
       " 'TECH',\n",
       " 'BIIB',\n",
       " 'BLK',\n",
       " 'BX',\n",
       " 'BA',\n",
       " 'BKNG',\n",
       " 'BWA',\n",
       " 'BXP',\n",
       " 'BSX',\n",
       " 'BMY',\n",
       " 'AVGO',\n",
       " 'BR',\n",
       " 'BRO',\n",
       " 'BF-B',\n",
       " 'BLDR',\n",
       " 'BG',\n",
       " 'CDNS',\n",
       " 'CZR',\n",
       " 'CPT',\n",
       " 'CPB',\n",
       " 'COF',\n",
       " 'CAH',\n",
       " 'KMX',\n",
       " 'CCL',\n",
       " 'CARR',\n",
       " 'CTLT',\n",
       " 'CAT',\n",
       " 'CBOE',\n",
       " 'CBRE',\n",
       " 'CDW',\n",
       " 'CE',\n",
       " 'COR',\n",
       " 'CNC',\n",
       " 'CNP',\n",
       " 'CF',\n",
       " 'CHRW',\n",
       " 'CRL',\n",
       " 'SCHW',\n",
       " 'CHTR',\n",
       " 'CVX',\n",
       " 'CMG',\n",
       " 'CB',\n",
       " 'CHD',\n",
       " 'CI',\n",
       " 'CINF',\n",
       " 'CTAS',\n",
       " 'CSCO',\n",
       " 'C',\n",
       " 'CFG',\n",
       " 'CLX',\n",
       " 'CME',\n",
       " 'CMS',\n",
       " 'KO',\n",
       " 'CTSH',\n",
       " 'CL',\n",
       " 'CMCSA',\n",
       " 'CMA',\n",
       " 'CAG',\n",
       " 'COP',\n",
       " 'ED',\n",
       " 'STZ',\n",
       " 'CEG',\n",
       " 'COO',\n",
       " 'CPRT',\n",
       " 'GLW',\n",
       " 'CTVA',\n",
       " 'CSGP',\n",
       " 'COST',\n",
       " 'CTRA',\n",
       " 'CCI',\n",
       " 'CSX',\n",
       " 'CMI',\n",
       " 'CVS',\n",
       " 'DHR',\n",
       " 'DRI',\n",
       " 'DVA',\n",
       " 'DAY',\n",
       " 'DE',\n",
       " 'DAL',\n",
       " 'XRAY',\n",
       " 'DVN',\n",
       " 'DXCM',\n",
       " 'FANG',\n",
       " 'DLR',\n",
       " 'DFS',\n",
       " 'DG',\n",
       " 'DLTR',\n",
       " 'D',\n",
       " 'DPZ',\n",
       " 'DOV',\n",
       " 'DOW',\n",
       " 'DHI',\n",
       " 'DTE',\n",
       " 'DUK',\n",
       " 'DD',\n",
       " 'EMN',\n",
       " 'ETN',\n",
       " 'EBAY',\n",
       " 'ECL',\n",
       " 'EIX',\n",
       " 'EW',\n",
       " 'EA',\n",
       " 'ELV',\n",
       " 'LLY',\n",
       " 'EMR',\n",
       " 'ENPH',\n",
       " 'ETR',\n",
       " 'EOG',\n",
       " 'EPAM',\n",
       " 'EQT',\n",
       " 'EFX',\n",
       " 'EQIX',\n",
       " 'EQR',\n",
       " 'ESS',\n",
       " 'EL',\n",
       " 'ETSY',\n",
       " 'EG',\n",
       " 'EVRG',\n",
       " 'ES',\n",
       " 'EXC',\n",
       " 'EXPE',\n",
       " 'EXPD',\n",
       " 'EXR',\n",
       " 'XOM',\n",
       " 'FFIV',\n",
       " 'FDS',\n",
       " 'FICO',\n",
       " 'FAST',\n",
       " 'FRT',\n",
       " 'FDX',\n",
       " 'FIS',\n",
       " 'FITB',\n",
       " 'FSLR',\n",
       " 'FE',\n",
       " 'FI',\n",
       " 'FLT',\n",
       " 'FMC',\n",
       " 'F',\n",
       " 'FTNT',\n",
       " 'FTV',\n",
       " 'FOXA',\n",
       " 'FOX',\n",
       " 'BEN',\n",
       " 'FCX',\n",
       " 'GRMN',\n",
       " 'IT',\n",
       " 'GEHC',\n",
       " 'GEN',\n",
       " 'GNRC',\n",
       " 'GD',\n",
       " 'GE',\n",
       " 'GIS',\n",
       " 'GM',\n",
       " 'GPC',\n",
       " 'GILD',\n",
       " 'GPN',\n",
       " 'GL',\n",
       " 'GS',\n",
       " 'HAL',\n",
       " 'HIG',\n",
       " 'HAS',\n",
       " 'HCA',\n",
       " 'PEAK',\n",
       " 'HSIC',\n",
       " 'HSY',\n",
       " 'HES',\n",
       " 'HPE',\n",
       " 'HLT',\n",
       " 'HOLX',\n",
       " 'HD',\n",
       " 'HON',\n",
       " 'HRL',\n",
       " 'HST',\n",
       " 'HWM',\n",
       " 'HPQ',\n",
       " 'HUBB',\n",
       " 'HUM',\n",
       " 'HBAN',\n",
       " 'HII',\n",
       " 'IBM',\n",
       " 'IEX',\n",
       " 'IDXX',\n",
       " 'ITW',\n",
       " 'ILMN',\n",
       " 'INCY',\n",
       " 'IR',\n",
       " 'PODD',\n",
       " 'INTC',\n",
       " 'ICE',\n",
       " 'IFF',\n",
       " 'IP',\n",
       " 'IPG',\n",
       " 'INTU',\n",
       " 'ISRG',\n",
       " 'IVZ',\n",
       " 'INVH',\n",
       " 'IQV',\n",
       " 'IRM',\n",
       " 'JBHT',\n",
       " 'JBL',\n",
       " 'JKHY',\n",
       " 'J',\n",
       " 'JNJ',\n",
       " 'JCI',\n",
       " 'JPM',\n",
       " 'JNPR',\n",
       " 'K',\n",
       " 'KVUE',\n",
       " 'KDP',\n",
       " 'KEY',\n",
       " 'KEYS',\n",
       " 'KMB',\n",
       " 'KIM',\n",
       " 'KMI',\n",
       " 'KLAC',\n",
       " 'KHC',\n",
       " 'KR',\n",
       " 'LHX',\n",
       " 'LH',\n",
       " 'LRCX',\n",
       " 'LW',\n",
       " 'LVS',\n",
       " 'LDOS',\n",
       " 'LEN',\n",
       " 'LIN',\n",
       " 'LYV',\n",
       " 'LKQ',\n",
       " 'LMT',\n",
       " 'L',\n",
       " 'LOW',\n",
       " 'LULU',\n",
       " 'LYB',\n",
       " 'MTB',\n",
       " 'MRO',\n",
       " 'MPC',\n",
       " 'MKTX',\n",
       " 'MAR',\n",
       " 'MMC',\n",
       " 'MLM',\n",
       " 'MAS',\n",
       " 'MA',\n",
       " 'MTCH',\n",
       " 'MKC',\n",
       " 'MCD',\n",
       " 'MCK',\n",
       " 'MDT',\n",
       " 'MRK',\n",
       " 'META',\n",
       " 'MET',\n",
       " 'MTD',\n",
       " 'MGM',\n",
       " 'MCHP',\n",
       " 'MU',\n",
       " 'MSFT',\n",
       " 'MAA',\n",
       " 'MRNA',\n",
       " 'MHK',\n",
       " 'MOH',\n",
       " 'TAP',\n",
       " 'MDLZ',\n",
       " 'MPWR',\n",
       " 'MNST',\n",
       " 'MCO',\n",
       " 'MS',\n",
       " 'MOS',\n",
       " 'MSI',\n",
       " 'MSCI',\n",
       " 'NDAQ',\n",
       " 'NTAP',\n",
       " 'NFLX',\n",
       " 'NEM',\n",
       " 'NWSA',\n",
       " 'NWS',\n",
       " 'NEE',\n",
       " 'NKE',\n",
       " 'NI',\n",
       " 'NDSN',\n",
       " 'NSC',\n",
       " 'NTRS',\n",
       " 'NOC',\n",
       " 'NCLH',\n",
       " 'NRG',\n",
       " 'NUE',\n",
       " 'NVDA',\n",
       " 'NVR',\n",
       " 'NXPI',\n",
       " 'ORLY',\n",
       " 'OXY',\n",
       " 'ODFL',\n",
       " 'OMC',\n",
       " 'ON',\n",
       " 'OKE',\n",
       " 'ORCL',\n",
       " 'OTIS',\n",
       " 'PCAR',\n",
       " 'PKG',\n",
       " 'PANW',\n",
       " 'PARA',\n",
       " 'PH',\n",
       " 'PAYX',\n",
       " 'PAYC',\n",
       " 'PYPL',\n",
       " 'PNR',\n",
       " 'PEP',\n",
       " 'PFE',\n",
       " 'PCG',\n",
       " 'PM',\n",
       " 'PSX',\n",
       " 'PNW',\n",
       " 'PXD',\n",
       " 'PNC',\n",
       " 'POOL',\n",
       " 'PPG',\n",
       " 'PPL',\n",
       " 'PFG',\n",
       " 'PG',\n",
       " 'PGR',\n",
       " 'PLD',\n",
       " 'PRU',\n",
       " 'PEG',\n",
       " 'PTC',\n",
       " 'PSA',\n",
       " 'PHM',\n",
       " 'QRVO',\n",
       " 'PWR',\n",
       " 'QCOM',\n",
       " 'DGX',\n",
       " 'RL',\n",
       " 'RJF',\n",
       " 'RTX',\n",
       " 'O',\n",
       " 'REG',\n",
       " 'REGN',\n",
       " 'RF',\n",
       " 'RSG',\n",
       " 'RMD',\n",
       " 'RVTY',\n",
       " 'RHI',\n",
       " 'ROK',\n",
       " 'ROL',\n",
       " 'ROP',\n",
       " 'ROST',\n",
       " 'RCL',\n",
       " 'SPGI',\n",
       " 'CRM',\n",
       " 'SBAC',\n",
       " 'SLB',\n",
       " 'STX',\n",
       " 'SRE',\n",
       " 'NOW',\n",
       " 'SHW',\n",
       " 'SPG',\n",
       " 'SWKS',\n",
       " 'SJM',\n",
       " 'SNA',\n",
       " 'SO',\n",
       " 'LUV',\n",
       " 'SWK',\n",
       " 'SBUX',\n",
       " 'STT',\n",
       " 'STLD',\n",
       " 'STE',\n",
       " 'SYK',\n",
       " 'SYF',\n",
       " 'SNPS',\n",
       " 'SYY',\n",
       " 'TMUS',\n",
       " 'TROW',\n",
       " 'TTWO',\n",
       " 'TPR',\n",
       " 'TRGP',\n",
       " 'TGT',\n",
       " 'TEL',\n",
       " 'TDY',\n",
       " 'TFX',\n",
       " 'TER',\n",
       " 'TSLA',\n",
       " 'TXN',\n",
       " 'TXT',\n",
       " 'TMO',\n",
       " 'TJX',\n",
       " 'TSCO',\n",
       " 'TT',\n",
       " 'TDG',\n",
       " 'TRV',\n",
       " 'TRMB',\n",
       " 'TFC',\n",
       " 'TYL',\n",
       " 'TSN',\n",
       " 'USB',\n",
       " 'UBER',\n",
       " 'UDR',\n",
       " 'ULTA',\n",
       " 'UNP',\n",
       " 'UAL',\n",
       " 'UPS',\n",
       " 'URI',\n",
       " 'UNH',\n",
       " 'UHS',\n",
       " 'VLO',\n",
       " 'VTR',\n",
       " 'VLTO',\n",
       " 'VRSN',\n",
       " 'VRSK',\n",
       " 'VZ',\n",
       " 'VRTX',\n",
       " 'VFC',\n",
       " 'VTRS',\n",
       " 'VICI',\n",
       " 'V',\n",
       " 'VMC',\n",
       " 'WRB',\n",
       " 'WAB',\n",
       " 'WBA',\n",
       " 'WMT',\n",
       " 'DIS',\n",
       " 'WBD',\n",
       " 'WM',\n",
       " 'WAT',\n",
       " 'WEC',\n",
       " 'WFC',\n",
       " 'WELL',\n",
       " 'WST',\n",
       " 'WDC',\n",
       " 'WRK',\n",
       " 'WY',\n",
       " 'WHR',\n",
       " 'WMB',\n",
       " 'WTW',\n",
       " 'GWW',\n",
       " 'WYNN',\n",
       " 'XEL',\n",
       " 'XYL',\n",
       " 'YUM',\n",
       " 'ZBRA',\n",
       " 'ZBH',\n",
       " 'ZION',\n",
       " 'ZTS']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols_list = sp500['Symbol'].unique().tolist()\n",
    "symbols_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a560a73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = '2024-02-01'\n",
    "start_date = pd.to_datetime(end_date)-pd.DateOffset(365*8)\n",
    "df = yf.download(tickers=symbols_list,\n",
    "                 start=start_date,\n",
    "                 end=end_date)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1d8f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.names = ['date', 'ticker']\n",
    "\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c34ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.get_level_values(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55746c31",
   "metadata": {},
   "source": [
    "## 2. Calculate features and technical indicators for each stock.\n",
    "\n",
    "* Garman-Klass Volatility\n",
    "* RSI\n",
    "* Bollinger Bands\n",
    "* ATR\n",
    "* MACD\n",
    "* Dollar Volume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c94feae",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\text{Garman-Klass Volatility} = \\frac{(\\ln(\\text{High}) - \\ln(\\text{Low}))^2}{2} - (2\\ln(2) - 1)(\\ln(\\text{Adj Close}) - \\ln(\\text{Open}))^2\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0b460f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "def get_slope(array):\n",
    "    y = np.array(array)\n",
    "    x = np.arange(len(y))\n",
    "    slope, intercept, r_val, p_val, std_err = linregress(x,y)\n",
    "    return (slope.mean()).std()\n",
    "\n",
    "def compute_atr(stock_data):\n",
    "    atr = pandas_ta.atr(high=stock_data['high'],\n",
    "                        low=stock_data['low'],\n",
    "                        close=stock_data['close'],\n",
    "                        length=14)\n",
    "    return atr.sub(atr.mean()).div(atr.std())\n",
    "\n",
    "def compute_macd(close):\n",
    "    macd = pandas_ta.macd(close=close, length=20).iloc[:,0]\n",
    "    return macd.sub(macd.mean()).div(macd.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481fd2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['garman_klass_vol'] = ((np.log(df['high'])-np.log(df['low']))**2)/2-(2*np.log(2)-1)*((np.log(df['adj close'])-np.log(df['open']))**2)\n",
    "\n",
    "df['atr'] = df.groupby(level=1, group_keys=False).apply(compute_atr)\n",
    "\n",
    "df['macd'] = df.groupby(level=1, group_keys=False)['adj close'].apply(compute_macd)\n",
    "\n",
    "df['rsi'] = df.groupby(level=1)['adj close'].transform(lambda x: pandas_ta.rsi(close=x, length=20))\n",
    "\n",
    "df['bb_low'] = df.groupby(level=1)['adj close'].transform(lambda x: pandas_ta.bbands(close=np.log1p(x), length=20).iloc[:,0])\n",
    "                                                          \n",
    "df['bb_mid'] = df.groupby(level=1)['adj close'].transform(lambda x: pandas_ta.bbands(close=np.log1p(x), length=20).iloc[:,1])\n",
    "                                                          \n",
    "df['bb_high'] = df.groupby(level=1)['adj close'].transform(lambda x: pandas_ta.bbands(close=np.log1p(x), length=20).iloc[:,2])\n",
    "\n",
    "df['dollar_volume'] = (df['adj close']*df['volume'])/1e6\n",
    "\n",
    "df['ma40'] = df.groupby(level=1, group_keys=False)['adj close'].transform(lambda x: pandas_ta.sma(close=np.log1p(x), length=40))\n",
    "\n",
    "df['ma80'] = df.groupby(level=1, group_keys=False)['adj close'].transform(lambda x: pandas_ta.sma(close=np.log1p(x), length=80))\n",
    "backrollingN = 6\n",
    "df['ma160'] = df.groupby(level=1, group_keys=False)['adj close'].transform(lambda x: pandas_ta.sma(close=np.log1p(x), length=160))\n",
    "# df['slopeMA40'] = df.groupby(level=1, group_keys=False)['ma40'].rolling(window=backrollingN).apply(get_slope, raw=True)\n",
    "# df['slopeMA80'] = df['MA80'].rolling(window=backrollingN).apply(get_slope, raw=True)\n",
    "# df['slopeMA160'] = df['MA160'].rolling(window=backrollingN).apply(get_slope, raw=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e7ef78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c735696b",
   "metadata": {},
   "source": [
    "## 3. Aggregate to monthly level and filter top 150 most liquid stocks for each month.\n",
    "\n",
    "* To reduce training time and experiment with features and strategies, we convert the business-daily data to month-end frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec67c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_cols = [c for c in df.columns.unique(0) if c not in ['dollar_volume', 'volume', 'open',\n",
    "                                                          'high', 'low', 'close']]\n",
    "\n",
    "data = (pd.concat([df.unstack('ticker')['dollar_volume'].resample('M').mean().stack('ticker').to_frame('dollar_volume'),\n",
    "                   df.unstack()[last_cols].resample('M').last().stack('ticker')],\n",
    "                  axis=1)).dropna()\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e632ffc7",
   "metadata": {},
   "source": [
    "* Calculate 5-year rolling average of dollar volume for each stocks before filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5208030",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['dollar_volume'] = (data.loc[:, 'dollar_volume'].unstack('ticker').rolling(5*12, min_periods=12).mean().stack())\n",
    "\n",
    "data['dollar_vol_rank'] = (data.groupby('date')['dollar_volume'].rank(ascending=False))\n",
    "\n",
    "data = data[data['dollar_vol_rank']<150].drop(['dollar_volume', 'dollar_vol_rank'], axis=1)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e13a3b",
   "metadata": {},
   "source": [
    "## 4. Calculate Monthly Returns for different time horizons as features.\n",
    "\n",
    "* To capture time series dynamics that reflect, for example, momentum patterns, we compute historical returns using the method .pct_change(lag), that is, returns over various monthly periods as identified by lags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda8d55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_returns(df):\n",
    "\n",
    "    outlier_cutoff = 0.005\n",
    "\n",
    "    lags = [1, 2, 3, 6, 9, 12]\n",
    "\n",
    "    for lag in lags:\n",
    "\n",
    "        df[f'return_{lag}m'] = (df['adj close']\n",
    "                              .pct_change(lag)\n",
    "                              .pipe(lambda x: x.clip(lower=x.quantile(outlier_cutoff),\n",
    "                                                     upper=x.quantile(1-outlier_cutoff)))\n",
    "                              .add(1)\n",
    "                              .pow(1/lag)\n",
    "                              .sub(1))\n",
    "    return df\n",
    "    \n",
    "    \n",
    "data = data.groupby(level=1, group_keys=False).apply(calculate_returns).dropna()\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df434b55",
   "metadata": {},
   "source": [
    "## 5. Download Fama-French Factors and Calculate Rolling Factor Betas.\n",
    "\n",
    "* We will introduce the Famaâ€”French data to estimate the exposure of assets to common risk factors using linear regression.\n",
    "\n",
    "* The five Famaâ€”French factors, namely market risk, size, value, operating profitability, and investment have been shown empirically to explain asset returns and are commonly used to assess the risk/return profile of portfolios. Hence, it is natural to include past factor exposures as financial features in models.\n",
    "\n",
    "* We can access the historical factor returns using the pandas-datareader and estimate historical exposures using the RollingOLS rolling linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64a7ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_data = web.DataReader('F-F_Research_Data_5_Factors_2x3',\n",
    "                               'famafrench',\n",
    "                               start='2010')[0].drop('RF', axis=1)\n",
    "\n",
    "factor_data.index = factor_data.index.to_timestamp()\n",
    "\n",
    "factor_data = factor_data.resample('M').last().div(100)\n",
    "\n",
    "factor_data.index.name = 'date'\n",
    "\n",
    "factor_data = factor_data.join(data['return_1m']).sort_index()\n",
    "\n",
    "factor_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8840bf3b",
   "metadata": {},
   "source": [
    "* Filter out stocks with less than 10 months of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d586d806",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = factor_data.groupby(level=1).size()\n",
    "\n",
    "valid_stocks = observations[observations >= 10]\n",
    "\n",
    "factor_data = factor_data[factor_data.index.get_level_values('ticker').isin(valid_stocks.index)]\n",
    "\n",
    "factor_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0107433",
   "metadata": {},
   "source": [
    "* Calculate Rolling Factor Betas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8364bbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = (factor_data.groupby(level=1,\n",
    "                            group_keys=False)\n",
    "         .apply(lambda x: RollingOLS(endog=x['return_1m'], \n",
    "                                     exog=sm.add_constant(x.drop('return_1m', axis=1)),\n",
    "                                     window=min(24, x.shape[0]),\n",
    "                                     min_nobs=len(x.columns)+1)\n",
    "         .fit(params_only=True)\n",
    "         .params\n",
    "         .drop('const', axis=1)))\n",
    "\n",
    "betas "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5491e61a",
   "metadata": {},
   "source": [
    "* Join the rolling factors data to the main features dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e169594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = ['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA']\n",
    "\n",
    "data = (data.join(betas.groupby('ticker').shift()))\n",
    "\n",
    "data.loc[:, factors] = data.groupby('ticker', group_keys=False)[factors].apply(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "data = data.drop('adj close', axis=1)\n",
    "\n",
    "data = data.dropna()\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81eeb7f6",
   "metadata": {},
   "source": [
    "### At this point we have to decide on what ML model and approach to use for predictions etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785bbfb3",
   "metadata": {},
   "source": [
    "## 6. For each month fit a K-Means Clustering Algorithm to group similar assets based on their features.\n",
    "\n",
    "### K-Means Clustering\n",
    "* You may want to initialize predefined centroids for each cluster based on your research.\n",
    "\n",
    "* For visualization purpose of this tutorial we will initially rely on the â€˜k-means++â€™ initialization.\n",
    "\n",
    "* Then we will pre-define our centroids for each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a94dc1a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "target_rsi_values = [30, 45, 55, 70]\n",
    "\n",
    "initial_centroids = np.zeros((len(target_rsi_values), 18))\n",
    "\n",
    "initial_centroids[:, 6] = target_rsi_values\n",
    "\n",
    "initial_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6323ab80",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# data = data.drop('cluster', axis=1)\n",
    "\n",
    "def get_clusters(df):\n",
    "    df['cluster'] = KMeans(n_clusters=4,\n",
    "                           random_state=0,\n",
    "                           init=initial_centroids).fit(df).labels_\n",
    "    return df\n",
    "\n",
    "data = data.dropna().groupby('date', group_keys=False).apply(get_clusters)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a66097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(data):\n",
    "\n",
    "    cluster_0 = data[data['cluster']==0]\n",
    "    cluster_1 = data[data['cluster']==1]\n",
    "    cluster_2 = data[data['cluster']==2]\n",
    "    cluster_3 = data[data['cluster']==3]\n",
    "\n",
    "    plt.scatter(cluster_0.iloc[:,0] , cluster_0.iloc[:,6] , color = 'red', label='cluster 0')\n",
    "    plt.scatter(cluster_1.iloc[:,0] , cluster_1.iloc[:,6] , color = 'green', label='cluster 1')\n",
    "    plt.scatter(cluster_2.iloc[:,0] , cluster_2.iloc[:,6] , color = 'blue', label='cluster 2')\n",
    "    plt.scatter(cluster_3.iloc[:,0] , cluster_3.iloc[:,6] , color = 'black', label='cluster 3')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984bd52f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "\n",
    "for i in data.index.get_level_values('date').unique().tolist():\n",
    "    \n",
    "    g = data.xs(i, level=0)\n",
    "    \n",
    "    plt.title(f'Date {i}')\n",
    "    \n",
    "    plot_clusters(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e52a4f",
   "metadata": {},
   "source": [
    "### Apply pre-defined centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d945fd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_rsi_values = [30, 45, 55, 70]\n",
    "\n",
    "initial_centroids = np.zeros((len(target_rsi_values), 18))\n",
    "\n",
    "initial_centroids[:, 6] = target_rsi_values\n",
    "\n",
    "initial_centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d28c49e",
   "metadata": {},
   "source": [
    "## 7. For each month select assets based on the cluster and form a portfolio based on Efficient Frontier max sharpe ratio optimization\n",
    "\n",
    "* First we will filter only stocks corresponding to the cluster we choose based on our hypothesis.\n",
    "\n",
    "* Momentum is persistent and my idea would be that stocks clustered around RSI 70 centroid should continue to outperform in the following month - thus I would select stocks corresponding to cluster 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4565941a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = data[data['cluster']==3].copy()\n",
    "\n",
    "filtered_df = filtered_df.reset_index(level=1)\n",
    "\n",
    "filtered_df.index = filtered_df.index+pd.DateOffset(1)\n",
    "\n",
    "filtered_df = filtered_df.reset_index().set_index(['date', 'ticker'])\n",
    "\n",
    "dates = filtered_df.index.get_level_values('date').unique().tolist()\n",
    "\n",
    "fixed_dates = {}\n",
    "\n",
    "for d in dates:\n",
    "    \n",
    "    fixed_dates[d.strftime('%Y-%m-%d')] = filtered_df.xs(d, level=0).index.tolist()\n",
    "    \n",
    "fixed_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097f9941",
   "metadata": {},
   "source": [
    "### Define portfolio optimization function\n",
    "\n",
    "* We will define a function which optimizes portfolio weights using PyPortfolioOpt package and EfficientFrontier optimizer to maximize the sharpe ratio.\n",
    "\n",
    "* To optimize the weights of a given portfolio we would need to supply last 1 year prices to the function.\n",
    "\n",
    "* Apply signle stock weight bounds constraint for diversification (minimum half of equaly weight and maximum 10% of portfolio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2888d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns\n",
    "\n",
    "def optimize_weights(prices, lower_bound=0):\n",
    "    \n",
    "    returns = expected_returns.mean_historical_return(prices=prices,\n",
    "                                                      frequency=252)\n",
    "    \n",
    "    cov = risk_models.sample_cov(prices=prices,\n",
    "                                 frequency=252)\n",
    "    \n",
    "    ef = EfficientFrontier(expected_returns=returns,\n",
    "                           cov_matrix=cov,\n",
    "                           weight_bounds=(lower_bound, .1),\n",
    "                           solver='SCS')\n",
    "    \n",
    "    weights = ef.max_sharpe()\n",
    "    \n",
    "    return ef.clean_weights()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd59c17",
   "metadata": {},
   "source": [
    "* Download Fresh Daily Prices Data only for short listed stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d737d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = data.index.get_level_values('ticker').unique().tolist()\n",
    "\n",
    "new_df = yf.download(tickers=stocks,\n",
    "                     start=data.index.get_level_values('date').unique()[0]-pd.DateOffset(months=12),\n",
    "                     end=data.index.get_level_values('date').unique()[-1])\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef0a767",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.names = ['date', 'ticker']\n",
    "\n",
    "df.columns = df.columns.str.lower()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8b906e",
   "metadata": {},
   "source": [
    "* Calculate daily returns for each stock which could land up in our portfolio.\n",
    "\n",
    "* Then loop over each month start, select the stocks for the month and calculate their weights for the next month.\n",
    "\n",
    "* If the maximum sharpe ratio optimization fails for a given month, apply equally-weighted weights.\n",
    "\n",
    "* Calculated each day portfolio return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a1120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_dataframe = np.log(new_df['Adj Close']).diff()\n",
    "\n",
    "portfolio_df = pd.DataFrame()\n",
    "\n",
    "for start_date in fixed_dates.keys():\n",
    "    \n",
    "    try:\n",
    "\n",
    "        end_date = (pd.to_datetime(start_date)+pd.offsets.MonthEnd(0)).strftime('%Y-%m-%d')\n",
    "\n",
    "        cols = fixed_dates[start_date]\n",
    "\n",
    "        optimization_start_date = (pd.to_datetime(start_date)-pd.DateOffset(months=12)).strftime('%Y-%m-%d')\n",
    "\n",
    "        optimization_end_date = (pd.to_datetime(start_date)-pd.DateOffset(days=1)).strftime('%Y-%m-%d')\n",
    "        \n",
    "        optimization_df = new_df[optimization_start_date:optimization_end_date]['Adj Close'][cols]\n",
    "        \n",
    "        success = False\n",
    "        try:\n",
    "            weights = optimize_weights(prices=optimization_df,\n",
    "                                   lower_bound=round(1/(len(optimization_df.columns)*2),3))\n",
    "\n",
    "            weights = pd.DataFrame(weights, index=pd.Series(0))\n",
    "            \n",
    "            success = True\n",
    "        except:\n",
    "            print(f'Max Sharpe Optimization failed for {start_date}, Continuing with Equal-Weights')\n",
    "        \n",
    "        if success==False:\n",
    "            weights = pd.DataFrame([1/len(optimization_df.columns) for i in range(len(optimization_df.columns))],\n",
    "                                     index=optimization_df.columns.tolist(),\n",
    "                                     columns=pd.Series(0)).T\n",
    "        \n",
    "        temp_df = returns_dataframe[start_date:end_date]\n",
    "\n",
    "        temp_df = temp_df.stack().to_frame('return').reset_index(level=0)\\\n",
    "                   .merge(weights.stack().to_frame('weight').reset_index(level=0, drop=True),\n",
    "                          left_index=True,\n",
    "                          right_index=True)\\\n",
    "                   .reset_index().set_index(['Date', 'index']).unstack().stack()\n",
    "\n",
    "        temp_df.index.names = ['date', 'ticker']\n",
    "\n",
    "        temp_df['weighted_return'] = temp_df['return']*temp_df['weight']\n",
    "\n",
    "        temp_df = temp_df.groupby(level=0)['weighted_return'].sum().to_frame('Strategy Return')\n",
    "\n",
    "        portfolio_df = pd.concat([portfolio_df, temp_df], axis=0)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "portfolio_df = portfolio_df.drop_duplicates()\n",
    "\n",
    "portfolio_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcced0d1",
   "metadata": {},
   "source": [
    "## 8. Visualize Portfolio returns and compare to SP500 returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bba264c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spy = yf.download(tickers='SPY',\n",
    "                  start='2015-01-01',\n",
    "                  end=dt.date.today())\n",
    "\n",
    "spy_ret = np.log(spy[['Adj Close']]).diff().dropna().rename({'Adj Close':'SPY Buy&Hold'}, axis=1)\n",
    "\n",
    "portfolio_df = portfolio_df.merge(spy_ret,\n",
    "                                  left_index=True,\n",
    "                                  right_index=True)\n",
    "\n",
    "portfolio_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07bec3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(portfolio_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1235b1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mtick\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "portfolio_cumulative_return = np.exp(np.log1p(portfolio_df).cumsum())-1\n",
    "\n",
    "portfolio_cumulative_return[:'2024-02-01'].plot(figsize=(16, 6))\n",
    "\n",
    "plt.title('Unsupervised Learning Trading Strategy Returns Over Time')\n",
    "\n",
    "plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(1))\n",
    "\n",
    "plt.ylabel('Return')\n",
    "\n",
    "plt.show()\n",
    "# portfolio_cumulative_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b332e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2ca999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21504e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770ff70f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31019716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1384dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645a75c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37a8a52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1f18007",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Investing Strategy\n",
    "\n",
    "## 1. Load Twitter Sentiment Data\n",
    "\n",
    "* Load the twitter sentiment dataset, set the index, calculat engagement ratio and filter out stocks with no significant twitter activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d947792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import yfinance as yf\n",
    "import os\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "data_folder = 'C:/Users/Jimmy/OneDrive/Documents/Quantitative-Finance/Analysis'\n",
    "\n",
    "sentiment_df = pd.read_csv(os.path.join(data_folder, 'sentiment_data.csv'))\n",
    "\n",
    "sentiment_df['date'] = pd.to_datetime(sentiment_df['date'])\n",
    "\n",
    "sentiment_df = sentiment_df.set_index(['date', 'symbol'])\n",
    "\n",
    "sentiment_df['engagement_ratio'] = sentiment_df['twitterComments']/sentiment_df['twitterLikes']\n",
    "\n",
    "sentiment_df = sentiment_df[(sentiment_df['twitterLikes']>20)&(sentiment_df['twitterComments']>10)]\n",
    "\n",
    "sentiment_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde71915",
   "metadata": {},
   "source": [
    "## 2. Aggregate Monthly and calculate average sentiment for the month\n",
    "\n",
    "* Aggregate on a monthly level and calculate average monthly metric, for the one we choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1158a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggragated_df = (sentiment_df.reset_index('symbol').groupby([pd.Grouper(freq='M'), 'symbol'])\n",
    "                    [['engagement_ratio']].mean())\n",
    "\n",
    "aggragated_df['rank'] = (aggragated_df.groupby(level=0)['engagement_ratio']\n",
    "                         .transform(lambda x: x.rank(ascending=False)))\n",
    "\n",
    "aggragated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d9f188",
   "metadata": {},
   "source": [
    "## 3. Select Top 5 Stocks based on their cross-sectional ranking for each month\n",
    "\n",
    "* Select top 5 stocks by rank for each month and fix the date to start at beginning of next month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac1dce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = aggragated_df[aggragated_df['rank']<6].copy()\n",
    "\n",
    "filtered_df = filtered_df.reset_index(level=1)\n",
    "\n",
    "filtered_df.index = filtered_df.index+pd.DateOffset(1)\n",
    "\n",
    "filtered_df = filtered_df.reset_index().set_index(['date', 'symbol'])\n",
    "\n",
    "filtered_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ecadd7",
   "metadata": {},
   "source": [
    "## 4. Extract the stocks to form portfolios with at the start of each new month\n",
    "\n",
    "* Create a dictionary containing start of month and corresponded selected stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc646c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = filtered_df.index.get_level_values('date').unique().tolist()\n",
    "\n",
    "fixed_dates = {}\n",
    "\n",
    "for d in dates:\n",
    "    \n",
    "    fixed_dates[d.strftime('%Y-%m-%d')] = filtered_df.xs(d, level=0).index.tolist()\n",
    "    \n",
    "fixed_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9750aea",
   "metadata": {},
   "source": [
    "## 5. Download fresh stock prices for only selected/shortlisted stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6503bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_list = sentiment_df.index.get_level_values('symbol').unique().tolist()\n",
    "\n",
    "prices_df = yf.download(tickers=stocks_list,BB\n",
    "                        start='2021-01-01',\n",
    "                        end='2023-03-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dff440",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64da79b",
   "metadata": {},
   "source": [
    "## 6. Calculate Portfolio Returns with monthly rebalancing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94971d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_df = np.log(prices_df['Adj Close']).diff().dropna()\n",
    "\n",
    "portfolio_df = pd.DataFrame()\n",
    "\n",
    "for start_date in fixed_dates.keys():\n",
    "    \n",
    "    end_date = (pd.to_datetime(start_date)+pd.offsets.MonthEnd()).strftime('%Y-%m-%d')\n",
    "    \n",
    "    cols = fixed_dates[start_date]\n",
    "    \n",
    "    temp_df = returns_df[start_date:end_date][cols].mean(axis=1).to_frame('portfolio_return')\n",
    "    \n",
    "    portfolio_df = pd.concat([portfolio_df, temp_df], axis=0)\n",
    "    \n",
    "portfolio_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f3f0d7",
   "metadata": {},
   "source": [
    "## 7. Download NASDAQ/QQQ prices and calculate returns to compare to our strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59d9f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "qqq_df = yf.download(tickers='QQQ',\n",
    "                     start='2021-01-01',\n",
    "                     end='2023-03-01')\n",
    "\n",
    "qqq_ret = np.log(qqq_df['Adj Close']).diff().to_frame('nasdaq_return')\n",
    "\n",
    "portfolio_df = portfolio_df.merge(qqq_ret,\n",
    "                                  left_index=True,\n",
    "                                  right_index=True)\n",
    "\n",
    "portfolio_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf728f75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "portfolios_cumulative_return = np.exp(np.log1p(portfolio_df).cumsum()).sub(1)\n",
    "\n",
    "portfolios_cumulative_return.plot(figsize=(16,6))\n",
    "\n",
    "plt.title('Twitter Engagement Ratio Strategy Return Over Time')\n",
    "\n",
    "plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(1))\n",
    "\n",
    "plt.ylabel('Return')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f62ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6d8cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d557c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7c05b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f25123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cfc09d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51f43be9",
   "metadata": {},
   "source": [
    "# Intraday Strategy Using GARCH Model\n",
    "\n",
    "\n",
    "* Using simulated daily data and intraday 5-min data.\n",
    "* Load Daily and 5-minute data.\n",
    "* Define function to fit GARCH model on the daily data and predict 1-day ahead volatility in a rolling window.\n",
    "* Calculate prediction premium and form a daily signal from it.\n",
    "* Merge with intraday data and calculate intraday indicators to form the intraday signal.\n",
    "* Generate the position entry and hold until the end of the day.\n",
    "* Calculate final strategy returns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46be3499",
   "metadata": {},
   "source": [
    "## 1. Load Simulated Daily and Simulated 5-minute data.\n",
    "\n",
    "* We are loading both datasets, set the indexes and calculate daily log returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21b8e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from arch import arch_model\n",
    "import pandas_ta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "data_folder = 'C:/Users/Jimmy/OneDrive/Documents/Quantitative-Finance/Analysis'\n",
    "\n",
    "daily_df = pd.read_csv(os.path.join(data_folder, 'simulated_daily_data.csv'))\n",
    "\n",
    "daily_df = daily_df.drop('Unnamed: 7', axis=1)\n",
    "\n",
    "daily_df['Date'] = pd.to_datetime(daily_df['Date'])\n",
    "\n",
    "daily_df = daily_df.set_index('Date')\n",
    "\n",
    "\n",
    "intraday_5min_df = pd.read_csv(os.path.join(data_folder, 'simulated_5min_data.csv'))\n",
    "\n",
    "intraday_5min_df = intraday_5min_df.drop('Unnamed: 6', axis=1)\n",
    "\n",
    "intraday_5min_df['datetime'] = pd.to_datetime(intraday_5min_df['datetime'])\n",
    "\n",
    "intraday_5min_df = intraday_5min_df.set_index('datetime')\n",
    "\n",
    "intraday_5min_df['date'] = pd.to_datetime(intraday_5min_df.index.date)\n",
    "\n",
    "intraday_5min_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0b9cc4",
   "metadata": {},
   "source": [
    "## 2. Define function to fit GARCH model and predict 1-day ahead volatility in a rolling window.\n",
    "\n",
    "* We are first calculating the 6-month rolling variance and then we are creating a function in a 6-month rolling window to fit a garch model and predict the next day variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed18e20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "daily_df['log_ret'] = np.log(daily_df['Adj Close']).diff()\n",
    "\n",
    "daily_df['variance'] = daily_df['log_ret'].rolling(180).var()\n",
    "\n",
    "daily_df = daily_df['2020':]\n",
    "\n",
    "def predict_volatility(x):\n",
    "    \n",
    "    best_model = arch_model(y=x,\n",
    "                            p=1,\n",
    "                            q=3).fit(update_freq=5,\n",
    "                                     disp='off')\n",
    "    \n",
    "    variance_forecast = best_model.forecast(horizon=1).variance.iloc[-1,0]\n",
    "\n",
    "    print(x.index[-1])\n",
    "    \n",
    "    return variance_forecast\n",
    "\n",
    "daily_df['predictions'] = daily_df['log_ret'].rolling(180).apply(lambda x: predict_volatility(x))\n",
    "\n",
    "daily_df = daily_df.dropna()\n",
    "\n",
    "daily_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d692730",
   "metadata": {},
   "source": [
    "## 3. Calculate prediction premium and form a daily signal from it.\n",
    "\n",
    "* We are calculating the prediction premium. And calculate its 6-month rolling standard deviation.\n",
    "\n",
    "* From this we are creating our daily signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb535a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df['prediction_premium'] = (daily_df['predictions']-daily_df['variance'])/daily_df['variance']\n",
    "\n",
    "daily_df['premium_std'] = daily_df['prediction_premium'].rolling(180).std()\n",
    "\n",
    "daily_df['signal_daily'] = daily_df.apply(lambda x: 1 if (x['prediction_premium']>x['premium_std'])\n",
    "                                         else (-1 if (x['prediction_premium']<x['premium_std']*-1) else np.nan),\n",
    "                                         axis=1)\n",
    "\n",
    "daily_df['signal_daily'] = daily_df['signal_daily'].shift()\n",
    "\n",
    "daily_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd44075",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "\n",
    "daily_df['signal_daily'].plot(kind='hist')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5467e501",
   "metadata": {},
   "source": [
    "## 4. Merge with intraday data and calculate intraday indicators to form the intraday signal.\n",
    "\n",
    "* Calculate all intraday indicators and intraday signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d99a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = intraday_5min_df.reset_index()\\\n",
    "                            .merge(daily_df[['signal_daily']].reset_index(),\n",
    "                                   left_on='date',\n",
    "                                   right_on='Date')\\\n",
    "                            .drop(['date','Date'], axis=1)\\\n",
    "                            .set_index('datetime')\n",
    "\n",
    "final_df['rsi'] = pandas_ta.rsi(close=final_df['close'],\n",
    "                                length=20)\n",
    "\n",
    "final_df['lband'] = pandas_ta.bbands(close=final_df['close'],\n",
    "                                     length=20).iloc[:,0]\n",
    "\n",
    "final_df['uband'] = pandas_ta.bbands(close=final_df['close'],\n",
    "                                     length=20).iloc[:,2]\n",
    "\n",
    "final_df['signal_intraday'] = final_df.apply(lambda x: 1 if (x['rsi']>70)&\n",
    "                                                            (x['close']>x['uband'])\n",
    "                                             else (-1 if (x['rsi']<30)&\n",
    "                                                         (x['close']<x['lband']) else np.nan),\n",
    "                                             axis=1)\n",
    "\n",
    "final_df['return'] = np.log(final_df['close']).diff()\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae154db7",
   "metadata": {},
   "source": [
    "## 5. Generate the position entry and hold until the end of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a4dcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['return_sign'] = final_df.apply(lambda x: -1 if (x['signal_daily']==1)&(x['signal_intraday']==1)\n",
    "                                        else (1 if (x['signal_daily']==-1)&(x['signal_intraday']==-1) else np.nan),\n",
    "                                        axis=1)\n",
    "\n",
    "final_df['return_sign'] = final_df.groupby(pd.Grouper(freq='D'))['return_sign']\\\n",
    "                                  .transform(lambda x: x.ffill())\n",
    "\n",
    "final_df['forward_return'] = final_df['return'].shift(-1)\n",
    "\n",
    "final_df['strategy_return'] = final_df['forward_return']*final_df['return_sign']\n",
    "\n",
    "daily_return_df = final_df.groupby(pd.Grouper(freq='D'))['strategy_return'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dd2e02",
   "metadata": {},
   "source": [
    "## 6. Calculate final strategy returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93caf5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mtick\n",
    "\n",
    "strategy_cumulative_return = np.exp(np.log1p(daily_return_df).cumsum()).sub(1)\n",
    "\n",
    "strategy_cumulative_return.plot(figsize=(16,6))\n",
    "\n",
    "plt.title('Intraday Strategy Returns')\n",
    "\n",
    "plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(1))\n",
    "\n",
    "plt.ylabel('Return')\n",
    "\n",
    "plt.show()\n",
    "                                                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b57aa20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6806c20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3787c376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0976c731",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
